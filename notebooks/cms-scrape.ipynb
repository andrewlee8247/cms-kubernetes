{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from google.cloud import storage\n",
    "from google.cloud.storage import Blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tryRequest(url, headers):\n",
    "    # Ping site until response status is 200, if not print fail\n",
    "    success = False\n",
    "    for _ in range(5):\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            success = True\n",
    "            return response\n",
    "            break\n",
    "        else:\n",
    "            print('Response received: %s. Retrying: %s'%(response.status_code, url))\n",
    "            success = False\n",
    "    if success == False:\n",
    "        return print(\"Failed to process the URL: \", url)\n",
    "\n",
    "def parseFiles():\n",
    "    st_time = datetime.now() #Start time\n",
    "    logging.basicConfig(filename='scrape.log', level=logging.DEBUG)\n",
    "    logging.info('Data download started at {}'.format(st_time))\n",
    "    \n",
    "    storage_client = storage.Client()\n",
    "    bucket_b = storage_client.get_bucket('cms-beneficiary')\n",
    "    bucket_i = storage_client.get_bucket('cms-inpatient')\n",
    "\n",
    "    dir = '/home/alee66831/cms-kubernetes/notebooks/files/'\n",
    "    url_path = 'https://www.cms.gov'\n",
    "    url = 'https://www.cms.gov/Research-Statistics-Data-and-Systems/Downloadable-Public-Use-Files/SynPUFs/DE_Syn_PUF'\n",
    "    headers = {'User-Agent': \"Chrome/54.0.2840.90\"}\n",
    "    # Grab all href from file summary page\n",
    "    response = tryRequest(url, headers)\n",
    "    html = response.content\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    tmpRow = soup.findAll('a')\n",
    "    count = 0\n",
    "\n",
    "    for i in range(len(tmpRow)):\n",
    "    # Extract all links to pages that have cms data files to download\n",
    "        try:\n",
    "            if tmpRow[i].contents[0].split(' ')[0] == 'DE1.0':\n",
    "                response = requests.get(url_path + tmpRow[i]['href'], headers=headers)\n",
    "                html = response.content\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "                tmpUrl = soup.findAll('a')\n",
    "                for k in range(len(tmpUrl)):\n",
    "                # Download all files, transform, process into parquet files, and upload to cloud storage\n",
    "                # all files in container are then removed\n",
    "                    try:\n",
    "                        if tmpUrl[k].contents[0].split(' ')[4] == 'Beneficiary':\n",
    "                            filepath = tmpUrl[k]['href']\n",
    "                            try:\n",
    "                                response = tryRequest(url_path + filepath, headers=headers)\n",
    "                                zip_path = dir + filepath.split('/')[-1]\n",
    "                                with open(zip_path, 'wb') as f:\n",
    "                                    f.write(response.content)\n",
    "                                filename = zipfile.ZipFile(zip_path, 'r').namelist()[0]\n",
    "                                with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "                                    zip_ref.extractall(dir)\n",
    "                                os.remove(zip_path)\n",
    "                                df = pd.read_csv(dir + filename, low_memory=False)\n",
    "                                os.remove(dir + filename)\n",
    "                                df['BENE_BIRTH_DT'] = pd.to_datetime(df['BENE_BIRTH_DT'].astype(str), format='%Y%m%d').dt.date\n",
    "                                df['BENE_BIRTH_DT'].fillna(np.nan, inplace=True)\n",
    "                                df['BENE_DEATH_DT'] = pd.to_datetime(df['BENE_DEATH_DT'].astype(str), format='%Y%m%d').dt.date\n",
    "                                df['BENE_DEATH_DT'].fillna(np.nan, inplace=True)\n",
    "                                df = df.apply(lambda x: x.astype('int16') if x.dtype == 'int64' else x)\n",
    "                                parq_file = filename.split('.')[0] + '.parquet'\n",
    "                                df.to_parquet(dir + parq_file)\n",
    "                                blob = Blob(parq_file, bucket_b)\n",
    "                                with open(dir + parq_file, 'rb') as my_file:\n",
    "                                    blob.upload_from_file(my_file)\n",
    "                                os.remove(dir + parq_file)\n",
    "                                count += 1\n",
    "                            except:\n",
    "                                logging.info(response)\n",
    "                        elif tmpUrl[k].contents[0].split(' ')[-3] == 'Inpatient':\n",
    "                            filepath = tmpUrl[k]['href']\n",
    "                            try:\n",
    "                                response = tryRequest(url_path + filepath, headers=headers)\n",
    "                                zip_path = dir + filepath.split('/')[-1]\n",
    "                                with open(zip_path, 'wb') as f:\n",
    "                                    f.write(response.content)\n",
    "                                filename = zipfile.ZipFile(zip_path, 'r').namelist()[0]\n",
    "                                with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "                                    zip_ref.extractall(dir)\n",
    "                                os.remove(zip_path)\n",
    "                                df = pd.read_csv(dir + filename, low_memory=False)\n",
    "                                os.remove(dir + filename)\n",
    "                                df['CLM_FROM_DT'] = pd.to_datetime(df['CLM_FROM_DT'].astype(str), format='%Y%m%d').dt.date\n",
    "                                df['CLM_FROM_DT'].fillna(np.nan, inplace=True)\n",
    "                                df['CLM_THRU_DT'] = pd.to_datetime(df['CLM_THRU_DT'].astype(str), format='%Y%m%d').dt.date\n",
    "                                df['CLM_THRU_DT'].fillna(np.nan, inplace=True)\n",
    "                                df['CLM_ADMSN_DT'] = pd.to_datetime(df['CLM_ADMSN_DT'].astype(str), format='%Y%m%d').dt.date\n",
    "                                df['CLM_ADMSN_DT'].fillna(np.nan, inplace=True)\n",
    "                                df['NCH_BENE_DSCHRG_DT'] = pd.to_datetime(df['NCH_BENE_DSCHRG_DT'].astype(str), format='%Y%m%d').dt.date\n",
    "                                df['NCH_BENE_DSCHRG_DT'].fillna(np.nan, inplace=True)\n",
    "                                df['AT_PHYSN_NPI'] = df['AT_PHYSN_NPI'].fillna(-1).astype('int64').astype(str).replace('-1', np.nan)\n",
    "                                df['OP_PHYSN_NPI'] = df['OP_PHYSN_NPI'].fillna(-1).astype('int64').astype(str).replace('-1', np.nan)\n",
    "                                df['OT_PHYSN_NPI'] = df['OT_PHYSN_NPI'].fillna(-1).astype('int64').astype(str).replace('-1', np.nan)\n",
    "                                df['SEGMENT'] = df['SEGMENT'].astype('int16')\n",
    "                                df.iloc[:,20:] = df.iloc[:,20:].apply(lambda x: x.astype(str) if x.dtype == 'float' else x)\n",
    "                                df['CLM_UTLZTN_DAY_CNT'] = df['CLM_UTLZTN_DAY_CNT'].fillna(0).astype('int16')\n",
    "                                parq_file = filename.split('.')[0] + '.parquet'\n",
    "                                df.to_parquet(dir + parq_file)\n",
    "                                blob = Blob(parq_file, bucket_i)\n",
    "                                with open(dir + parq_file, 'rb') as my_file:\n",
    "                                    blob.upload_from_file(my_file)\n",
    "                                os.remove(dir + parq_file)\n",
    "                                count += 1\n",
    "                            except:\n",
    "                                logging.info(response)    \n",
    "                    except:\n",
    "                        try:\n",
    "                            if tmpUrl[k].contents[1].split('(', 1)[1].split(')')[0] == 'ZIP':\n",
    "                                if tmpUrl[k]['href'].split('_')[5] == 'Inpatient':\n",
    "                                    filepath = tmpUrl[k]['href']\n",
    "                                    try:\n",
    "                                        response = tryRequest(url_path + filepath, headers=headers)\n",
    "                                        zip_path = dir + filepath.split('/')[-1]\n",
    "                                        with open(zip_path, 'wb') as f:\n",
    "                                            f.write(response.content)\n",
    "                                        filename = zipfile.ZipFile(zip_path, 'r').namelist()[0]\n",
    "                                        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "                                            zip_ref.extractall(dir)\n",
    "                                        os.remove(zip_path)\n",
    "                                        df = pd.read_csv(dir + filename, low_memory=False)\n",
    "                                        os.remove(dir + filename)\n",
    "                                        df['CLM_FROM_DT'] = pd.to_datetime(df['CLM_FROM_DT'].astype(str), format='%Y%m%d').dt.date\n",
    "                                        df['CLM_FROM_DT'].fillna(np.nan, inplace=True)\n",
    "                                        df['CLM_THRU_DT'] = pd.to_datetime(df['CLM_THRU_DT'].astype(str), format='%Y%m%d').dt.date\n",
    "                                        df['CLM_THRU_DT'].fillna(np.nan, inplace=True)\n",
    "                                        df['CLM_ADMSN_DT'] = pd.to_datetime(df['CLM_ADMSN_DT'].astype(str), format='%Y%m%d').dt.date\n",
    "                                        df['CLM_ADMSN_DT'].fillna(np.nan, inplace=True)\n",
    "                                        df['NCH_BENE_DSCHRG_DT'] = pd.to_datetime(df['NCH_BENE_DSCHRG_DT'].astype(str), format='%Y%m%d').dt.date\n",
    "                                        df['NCH_BENE_DSCHRG_DT'].fillna(np.nan, inplace=True)\n",
    "                                        df['AT_PHYSN_NPI'] = df['AT_PHYSN_NPI'].fillna(-1).astype('int64').astype(str).replace('-1', np.nan)\n",
    "                                        df['OP_PHYSN_NPI'] = df['OP_PHYSN_NPI'].fillna(-1).astype('int64').astype(str).replace('-1', np.nan)\n",
    "                                        df['OT_PHYSN_NPI'] = df['OT_PHYSN_NPI'].fillna(-1).astype('int64').astype(str).replace('-1', np.nan)\n",
    "                                        df['SEGMENT'] = df['SEGMENT'].astype('int16')\n",
    "                                        df.iloc[:,20:] = df.iloc[:,20:].apply(lambda x: x.astype(str) if x.dtype == 'float' else x)\n",
    "                                        df['CLM_UTLZTN_DAY_CNT'] = df['CLM_UTLZTN_DAY_CNT'].fillna(0).astype('int16')\n",
    "                                        parq_file = filename.split('.')[0] + '.parquet'\n",
    "                                        df.to_parquet(dir + parq_file)\n",
    "                                        blob = Blob(parq_file, bucket_i)\n",
    "                                        with open(dir + parq_file, 'rb') as my_file:\n",
    "                                            blob.upload_from_file(my_file)\n",
    "                                        os.remove(dir + parq_file)\n",
    "                                        count += 1\n",
    "                                    except:\n",
    "                                        logging.info(response)\n",
    "                                elif tmpUrl[k]['href'].split('_')[3] == 'Beneficiary':\n",
    "                                    filepath = tmpUrl[k]['href']\n",
    "                                    try:\n",
    "                                        response = tryRequest(url_path + filepath, headers=headers)\n",
    "                                        zip_path = dir + filepath.split('/')[-1]\n",
    "                                        with open(zip_path, 'wb') as f:\n",
    "                                            f.write(response.content)\n",
    "                                        filename = zipfile.ZipFile(zip_path, 'r').namelist()[0]\n",
    "                                        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "                                            zip_ref.extractall(dir)\n",
    "                                        os.remove(zip_path)\n",
    "                                        df = pd.read_csv(dir + filename, low_memory=False)\n",
    "                                        os.remove(dir + filename)\n",
    "                                        df['BENE_BIRTH_DT'] = pd.to_datetime(df['BENE_BIRTH_DT'].astype(str), format='%Y%m%d').dt.date\n",
    "                                        df['BENE_BIRTH_DT'].fillna(np.nan, inplace=True)\n",
    "                                        df['BENE_DEATH_DT'] = pd.to_datetime(df['BENE_DEATH_DT'].astype(str), format='%Y%m%d').dt.date\n",
    "                                        df['BENE_DEATH_DT'].fillna(np.nan, inplace=True)\n",
    "                                        df = df.apply(lambda x: x.astype('int16') if x.dtype == 'int64' else x)\n",
    "                                        parq_file = filename.split('.')[0] + '.parquet'\n",
    "                                        df.to_parquet(dir + parq_file)\n",
    "                                        blob = Blob(parq_file, bucket_b)\n",
    "                                        with open(dir + parq_file, 'rb') as my_file:\n",
    "                                            blob.upload_from_file(my_file)\n",
    "                                        os.remove(dir + parq_file)\n",
    "                                        count += 1\n",
    "                                    except:\n",
    "                                        logging.info(response)\n",
    "                        except:\n",
    "                            pass\n",
    "                                    \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    # Log completion\n",
    "    logging.info('{} total files processed'.format(count))\n",
    "    fin_time = datetime.now()\n",
    "    execution_time = fin_time - st_time\n",
    "    logging.info('Total execution time: {}'.format(str(execution_time)))\n",
    "    \n",
    "    return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
